Ось приклад файлу `TESTING.md`, адаптованого під твої сервіси та тести, з описом сценаріїв для unit та integration тестів:

````markdown
# Документація тестування

## Запуск тестів

### Локально
1. Активуйте віртуальне середовище:
```bash
# Windows
.venv\Scripts\activate
# Linux / Mac
source .venv/bin/activate
Встановіть залежності (якщо ще не зроблено):
```

```bash
Копіювати код
pip install -r requirements.txt
Запустіть всі тести:
```
```bash
Копіювати код
pytest
Запустіть тести з покриттям коду та згенеруйте HTML-звіт:
```
```bash
Копіювати код
pytest --cov=app --cov-report=html
Для запуску конкретного тесту або файлу:
```
```bash
Копіювати код
pytest tests/unit/test_feedback_rules.py
pytest tests/integration/test_api_cart.py::test_add_item_to_cart_new_item
У Docker / контейнері
Створіть образ (якщо ще не зроблено):
```
```bash
Копіювати код
docker build -t myapp:test .
Запустіть контейнер з тестами:
```
```bash
Копіювати код
docker run --rm myapp:test pytest
Якщо потрібно побачити покриття коду:
```
```bash
Копіювати код
docker run --rm myapp:test pytest --cov=app --cov-report=term-missing
Для інтеграційних тестів у контейнері переконайтеся, що контейнер має доступ до тестової БД (можна використати Docker Compose з сервісом PostgreSQL або SQLite).
```
### Всі тести
```bash
pytest
````

### З покриттям коду

```bash
pytest --cov=app --cov-report=html
```

---

## Опис тестових сценаріїв

### Unit тести

#### FeedbackService

* **get_all_feedbacks_service**
  Перевіряє отримання всіх відгуків.
  Очікуваний результат: список об'єктів відгуків.

* **get_feedback_by_id_service**
  Перевіряє отримання відгуку по ID.
  Очікуваний результат: об'єкт відгуку або None + повідомлення "Feedback not found".

* **create_feedback_service**
  Перевіряє створення відгуку.
  Очікуваний результат: об'єкт відгуку або помилка при короткому заголовку/тексті або відсутності user_id.

* **update_feedback_service**
  Перевіряє оновлення відгуку.
  Очікуваний результат: об'єкт відгуку або помилка при невірних даних.

* **delete_feedback_service**
  Перевіряє видалення відгуку по ID.
  Очікуваний результат: True + повідомлення успіху або False + повідомлення про неіснуючий відгук.

#### DesktopService

* **create_desktop_service**
  Перевіряє створення нового десктопу з валідацією назви, ціни та зображення.
  Очікуваний результат: об'єкт десктопу або помилка валідації.

* **update_desktop_service**
  Перевіряє оновлення десктопу з валідацією ціни та зображення.
  Очікуваний результат: об'єкт десктопу або помилка.

* **delete_desktop_service**
  Перевіряє видалення десктопу по ID.
  Очікуваний результат: True або False + повідомлення.

#### UserService

* **authorize_user**
  Перевіряє логін користувача з правильним/неправильним паролем та відсутнім юзером.
  Очікуваний результат: User або None.

* **registration**
  Перевіряє реєстрацію користувача з усіма даними та при пропущених полях.
  Очікуваний результат: User або повідомлення про помилку.

* **request_password_reset**
  Перевіряє запит на скидання пароля.
  Очікуваний результат: токен або повідомлення про неіснуючий email.

* **reset_password_with_token**
  Перевіряє зміну пароля через токен, невірні паролі або недійсний токен.
  Очікуваний результат: успіх або повідомлення про помилку.

#### OrdersService

* **edit_status_order**
  Перевіряє оновлення статусу замовлення.
  Очікуваний результат: новий статус або повідомлення про помилку при недопустимому статусі.

---

### Integration тести

#### CartService

* **get_cart**
  Перевіряє отримання кошика користувача з товарами та total.
  Очікуваний результат: словник з items та total.

* **add_item_to_cart**
  Перевіряє додавання нового товару та збільшення кількості існуючого.
  Очікуваний результат: CartItem з правильною quantity.

* **remove_item_from_cart**
  Перевіряє видалення товару з кошика.
  Очікуваний результат: True та відсутність CartItem у базі.

* **clear_cart**
  Перевіряє очищення кошика.
  Очікуваний результат: порожній список товарів.

* **update_item_quantity**
  Перевіряє зміну кількості товару.
  Очікуваний результат: CartItem з новою quantity.

#### Feedback, Desktop, News, Orders

* Integration тести аналогічні unit-тестам, але перевіряють роботу сервісів разом з базою або API (за потреби).

---

### Примітки

* Використовувати `pytest` разом з `pytest-mock` або `unittest.mock` для моків.
* Для інтеграційних тестів бажано піднімати тестову БД або використовувати транзакції, щоб кожен тест був ізольований.
* Тести повинні перевіряти не тільки успішні сценарії, але й помилки валідації та граничні випадки.
